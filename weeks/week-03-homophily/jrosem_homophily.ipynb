{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6kbHmjV7c1g2",
        "OGcD_z06z3bv",
        "QIJRLkGFHDrn",
        "ajp6nBz_HVB2",
        "zlypqrMjHlnA",
        "i9tlQ6vl7w-r",
        "Krq1WbCCIMxv",
        "hYopMJm6HhXz",
        "c17F4CgfdBMO",
        "RKVktcecJGXa",
        "K6MUIk-gJbGN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DO NOT EDIT: Libraries & Global Parameters"
      ],
      "metadata": {
        "id": "m0nFzn9fHjVq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "2hQPYL2xHgAq"
      },
      "outputs": [],
      "source": [
        "import random, json, math, statistics, textwrap\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from dataclasses import dataclass, field\n",
        "from openai import OpenAI\n",
        "from re import TEMPLATE\n",
        "\n",
        "!pip install -q autogen~=0.2 > /dev/null 2>&1\n",
        "\n",
        "try:\n",
        "    from autogen import AssistantAgent, GroupChatManager, GroupChat\n",
        "except ModuleNotFoundError as e:\n",
        "    raise ImportError(\"The 'autogen' module is not installed. Please install it using 'pip install pyautogen'.\") from e\n",
        "\n",
        "MODEL = \"gpt-5-mini\"\n",
        "API_KEY = \"\"\n",
        "BASE_URL = \"https://api.openai.com/v1\"\n",
        "\n",
        "llm_config = {\n",
        "    \"model\": MODEL,\n",
        "    \"api_key\": API_KEY,\n",
        "    \"base_url\": BASE_URL,\n",
        "}\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=API_KEY,\n",
        "    base_url=llm_config[\"base_url\"]\n",
        ")\n",
        "\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDIT: Overview of All Attributes\n",
        "\n",
        "Here, you can view and edit all attributes (incl. their anchors) that we can use for later simulations and persona construction."
      ],
      "metadata": {
        "id": "bM35WIhzc0GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Personal attributes\n",
        "ATTRS = {\n",
        "    # --- Surface-level attributes (readily observable or easily inferred) ---\n",
        "    \"age\":                {\"min\":0,\"max\":100,\"low\":\"very young (≈18)\",\"high\":\"older (≈70)\"},\n",
        "    \"gender_expression\":  {\"min\":0,\"max\":100,\"low\":\"traditionally feminine\",\"high\":\"traditionally masculine\"},\n",
        "    \"education\":          {\"min\":0,\"max\":100,\"low\":\"no formal education\",\"high\":\"very high (PhD/prof.)\"},\n",
        "    \"occupation_status\":  {\"min\":0,\"max\":100,\"low\":\"unemployed / entry-level\",\"high\":\"senior professional / executive\"},\n",
        "    \"income\":             {\"min\":0,\"max\":100,\"low\":\"very low income\",\"high\":\"very high income/wealth\"},\n",
        "    \"urbanicity\":         {\"min\":0,\"max\":100,\"low\":\"very rural\",\"high\":\"very urban (dense metro)\"},\n",
        "    \"ethnocultural_identity\": {\"min\":0,\"max\":100,\"low\":\"monocultural / traditional\",\"high\":\"multicultural / global\"},\n",
        "    \"communication_style\": {\"min\":0,\"max\":100,\"low\":\"reserved / indirect\",\"high\":\"expressive / direct\"},\n",
        "\n",
        "    # --- Deep-level attributes (values, beliefs, personality, cognition) ---\n",
        "    \"political_ideology\": {\"min\":0,\"max\":100,\"low\":\"very liberal / progressive\",\"high\":\"very conservative / traditional\"},\n",
        "    \"religiosity\":        {\"min\":0,\"max\":100,\"low\":\"non-religious\",\"high\":\"highly devout\"},\n",
        "    \"cultural_openness\":  {\"min\":0,\"max\":100,\"low\":\"insular / local\",\"high\":\"cosmopolitan / multilingual\"},\n",
        "    \"risk_taking\":        {\"min\":0,\"max\":100,\"low\":\"risk-averse\",\"high\":\"risk-seeking\"},\n",
        "    \"extraversion\":       {\"min\":0,\"max\":100,\"low\":\"very introverted\",\"high\":\"very extraverted\"},\n",
        "    \"agreeableness\":      {\"min\":0,\"max\":100,\"low\":\"abrasive / competitive\",\"high\":\"cooperative / warm\"},\n",
        "    \"conscientiousness\":  {\"min\":0,\"max\":100,\"low\":\"disorganized / spontaneous\",\"high\":\"disciplined / structured\"},\n",
        "    \"openness\":           {\"min\":0,\"max\":100,\"low\":\"closed to novelty\",\"high\":\"highly open to ideas / experiences\"},\n",
        "    \"creativity\":         {\"min\":0,\"max\":100,\"low\":\"prefers convention\",\"high\":\"original / imaginative\"},\n",
        "    \"moral_foundation\":   {\"min\":0,\"max\":100,\"low\":\"care/fairness emphasis\",\"high\":\"loyalty/authority emphasis\"},\n",
        "    \"values_independence\":{\"min\":0,\"max\":100,\"low\":\"prefers interdependence\",\"high\":\"prefers autonomy / self-direction\"},\n",
        "    \"work_centrality\":    {\"min\":0,\"max\":100,\"low\":\"job is a means\",\"high\":\"job is core identity / purpose\"},\n",
        "    \"tech_adoption\":      {\"min\":0,\"max\":100,\"low\":\"avoids new tech\",\"high\":\"early adopter / tech enthusiast\"},\n",
        "    \"environmentalism\":   {\"min\":0,\"max\":100,\"low\":\"unconcerned\",\"high\":\"very concerned / active\"},\n",
        "    \"intellectual_style\": {\"min\":0,\"max\":100,\"low\":\"concrete / practical thinker\",\"high\":\"abstract / theoretical thinker\"},\n",
        "    \"emotional_expressivity\":{\"min\":0,\"max\":100,\"low\":\"restrained / stoic\",\"high\":\"emotionally expressive / open\"},\n",
        "    \"humor_style\":        {\"min\":0,\"max\":100,\"low\":\"dry / sarcastic\",\"high\":\"playful / affiliative\"},\n",
        "}"
      ],
      "metadata": {
        "id": "iq2I6i2xH06r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DO NOT EDIT: Helper to Create Agents"
      ],
      "metadata": {
        "id": "6kbHmjV7c1g2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Active personal attribute selection for this run\n",
        "ACTIVE_ATTRS = []  # filled by set_active_attrs()\n",
        "\n",
        "def set_active_attrs(attrs):\n",
        "    \"\"\"Declare which attributes are active for this run, in the order that values will be provided.\"\"\"\n",
        "    missing = [a for a in attrs if a not in ATTRS]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Unknown attribute(s): {missing}\")\n",
        "    if len(set(attrs)) != len(attrs):\n",
        "        raise ValueError(\"Duplicate attributes in active set.\")\n",
        "    global ACTIVE_ATTRS\n",
        "    ACTIVE_ATTRS = list(attrs)\n",
        "\n",
        "# Utilities\n",
        "_NA_STRINGS = {\"na\", \"n/a\", \"\"}\n",
        "\n",
        "def _is_na(x):\n",
        "    if x is None:\n",
        "        return True\n",
        "    if isinstance(x, float) and math.isnan(x):\n",
        "        return True\n",
        "    if isinstance(x, str) and x.strip().lower() in _NA_STRINGS:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def _validate(attr, value):\n",
        "    lo, hi = ATTRS[attr][\"min\"], ATTRS[attr][\"max\"]\n",
        "    if not (lo <= value <= hi):\n",
        "        raise ValueError(f\"Value for {attr}={value} must be in [{lo}, {hi}]\")\n",
        "\n",
        "# Agent representation\n",
        "@dataclass(frozen=True)\n",
        "class Agent:\n",
        "    name: str\n",
        "    attributes: dict = field(default_factory=dict)\n",
        "\n",
        "# Core creator: supply exactly len(ACTIVE_ATTRS) values in order\n",
        "def create_agent_from_values(values, name=None):\n",
        "    \"\"\"\n",
        "    values: iterable with length == len(ACTIVE_ATTRS)\n",
        "            Use NA markers (None, '', 'NA', 'n/a', float('nan')) to skip an attribute.\n",
        "    \"\"\"\n",
        "    if not ACTIVE_ATTRS:\n",
        "        raise RuntimeError(\"ACTIVE_ATTRS is empty. Call set_active_attrs([...]) first.\")\n",
        "    values = list(values)\n",
        "    if len(values) != len(ACTIVE_ATTRS):\n",
        "        raise ValueError(f\"Expected {len(ACTIVE_ATTRS)} values, got {len(values)}.\")\n",
        "\n",
        "    agent_attrs = {}\n",
        "    for attr, val in zip(ACTIVE_ATTRS, values):\n",
        "        if _is_na(val):\n",
        "            # leave attribute undefined (skip)\n",
        "            continue\n",
        "        if not isinstance(val, (int, float)):\n",
        "            raise TypeError(f\"Non-numeric value for {attr}: {val!r}\")\n",
        "        _validate(attr, float(val))\n",
        "        agent_attrs[attr] = float(val)\n",
        "\n",
        "    return Agent(name=name or \"agent\", attributes=agent_attrs)"
      ],
      "metadata": {
        "id": "cPBhDxJtc48h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DO NOT EDIT: Helper for Output Overview"
      ],
      "metadata": {
        "id": "OGcD_z06z3bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_agents(reference_agent, other_agents, active_attrs=None):\n",
        "    \"\"\"\n",
        "    Display the original attribute values (not distances) for each agent as text.\n",
        "    \"\"\"\n",
        "    if active_attrs is None:\n",
        "        active_attrs = ACTIVE_ATTRS\n",
        "\n",
        "    if not active_attrs:\n",
        "        raise ValueError(\"No active attributes to display. Did you call set_active_attrs([...])?\")\n",
        "\n",
        "    # Build header\n",
        "    agent_names = [reference_agent.name] + list(other_agents.keys())\n",
        "    header = [\"Attribute\"] + agent_names\n",
        "    rows = []\n",
        "\n",
        "    # Build rows for each attribute\n",
        "    for a in active_attrs:\n",
        "        vals = [reference_agent.attributes.get(a)]\n",
        "        for _, agent in other_agents.items():\n",
        "            vals.append(agent.attributes.get(a))\n",
        "        rows.append([a] + vals)\n",
        "\n",
        "    # Determine column widths for pretty printing\n",
        "    col_widths = [max(len(str(x)) for x in col) + 2 for col in zip(header, *rows)]\n",
        "\n",
        "    # Helper for safe formatting\n",
        "    def fmt(val):\n",
        "        if val is None or (isinstance(val, float) and math.isnan(val)):\n",
        "            return \"NA\"\n",
        "        return f\"{val:.1f}\" if isinstance(val, (int, float)) else str(val)\n",
        "\n",
        "    # Print table header\n",
        "    print(\"\\n\\n=== Actual Attribute Values ===\\n\")\n",
        "    print(\"\".join(h.ljust(w) for h, w in zip(header, col_widths)))\n",
        "    print(\"-\" * sum(col_widths))\n",
        "\n",
        "    # Print each row\n",
        "    for r in rows:\n",
        "        print(\"\".join(fmt(x).ljust(w) for x, w in zip(r, col_widths)))"
      ],
      "metadata": {
        "id": "bUswksW0z23z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIM 1: Similarity Perceptions\n",
        "\n",
        "In this simulation, we supply quantitative attribute scores to create 2 personas with an LLM. Then, we let one generative agent be one of the personas and let them evaluate in terms of similarity the other persona.\n",
        "\n",
        "Broadly speaking, we can examine based on the alignment of which attributes a generative agent forms perceptions of similarity.\n",
        "\n",
        "However, we should be mindful that in real world, narrative descriptions of others will not be easily available, and we have to form our impressions of others based on cues we observe. Thus, we might consider this simulation a \"baseline\" test of similarity perceptions in an (even more) artificial setting."
      ],
      "metadata": {
        "id": "CsG7MO83Gofr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDIT: Define Attributes\n",
        "\n",
        "Here, you pick the attributes that you want Persona 1 (the focal agent) and Persona 2 to have.\n",
        "\n",
        "You can add more/different attributes, as well as different values for the attributes, if desired."
      ],
      "metadata": {
        "id": "IN310pA7G7Jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick the active attributes\n",
        "set_active_attrs([\"conscientiousness\", \"agreeableness\", \"openness\", \"extraversion\", \"income\"])\n",
        "\n",
        "# Set values for active attributes; use \"NA\" to leave an attribute undefined.\n",
        "persona_1_sim1     = create_agent_from_values([30, 50, 50, 50, 30], name=\"persona_1\")\n",
        "persona_2_sim1     = create_agent_from_values([70, 50, 50, 50, 70], name=\"persona_2\")"
      ],
      "metadata": {
        "id": "27FSSlG3F4Yh"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DO NOT EDIT: LLM Prompt for Narratives"
      ],
      "metadata": {
        "id": "QIJRLkGFHDrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concat\n",
        "agents_text_sim1 = \"\\n\\nPersona 1's personality:\\n\" + \"\\n\".join(\n",
        "    [\n",
        "        f\"  - {a}: {persona_1_sim1.attributes.get(a, 'UNDEFINED')}/100  (0={ATTRS[a]['low']}, 100={ATTRS[a]['high']})\"\n",
        "        for a in ACTIVE_ATTRS\n",
        "    ]\n",
        ")\n",
        "agents_text_sim1 += \"\\n\\nPersona 2's personality:\\n\" + \"\\n\".join(\n",
        "    [\n",
        "        f\"  - {a}: {persona_2_sim1.attributes.get(a, 'UNDEFINED')}/100  (0={ATTRS[a]['low']}, 100={ATTRS[a]['high']})\"\n",
        "        for a in ACTIVE_ATTRS\n",
        "    ]\n",
        ")\n",
        "\n",
        "task_prompt_narrative_sim1 = \"\"\"Convert numeric profiles into grounded and detailed personality narratives (10 sentences each).\n",
        "Use the anchors to interpret direction.\n",
        "Narrative must not contain EXPLICITLY information about the anchors or scales that it were used to generate it (e.g., no mention of provided scores/provided attributes/etc.).\n",
        "Instead, each narrative should IMPLICITLY reflect the numeric profiles and their anchors.\"\"\"\n",
        "\n",
        "output_format_narrative_sim1 = \"\"\"Return STRICT JSON with three string fields (no markdown): {{\"persona_1\": \"<10 sentences in SECOND PERSON (you/yours/etc.)>\", \"persona_2\": \"<10 sentences in THIRD PERSON (they/them; NO first-person>\"}}\"\"\"\n",
        "\n",
        "PROMPT_narrative_sim1 = task_prompt_narrative_sim1 + agents_text_sim1 + \"\\n\\n\" + output_format_narrative_sim1\n",
        "\n",
        "print(PROMPT_narrative_sim1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p14N3C7cGC8x",
        "outputId": "407335f9-3a8c-46a4-80ae-fb83d5a767b0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert numeric profiles into grounded and detailed personality narratives (10 sentences each).\n",
            "Use the anchors to interpret direction.\n",
            "Narrative must not contain EXPLICITLY information about the anchors or scales that it were used to generate it (e.g., no mention of provided scores/provided attributes/etc.).\n",
            "Instead, each narrative should IMPLICITLY reflect the numeric profiles and their anchors.\n",
            "\n",
            "Persona 1's personality:\n",
            "  - conscientiousness: 30.0/100  (0=disorganized / spontaneous, 100=disciplined / structured)\n",
            "  - agreeableness: 50.0/100  (0=abrasive / competitive, 100=cooperative / warm)\n",
            "  - openness: 50.0/100  (0=closed to novelty, 100=highly open to ideas / experiences)\n",
            "  - extraversion: 50.0/100  (0=very introverted, 100=very extraverted)\n",
            "  - income: 30.0/100  (0=very low income, 100=very high income/wealth)\n",
            "\n",
            "Persona 2's personality:\n",
            "  - conscientiousness: 70.0/100  (0=disorganized / spontaneous, 100=disciplined / structured)\n",
            "  - agreeableness: 50.0/100  (0=abrasive / competitive, 100=cooperative / warm)\n",
            "  - openness: 50.0/100  (0=closed to novelty, 100=highly open to ideas / experiences)\n",
            "  - extraversion: 50.0/100  (0=very introverted, 100=very extraverted)\n",
            "  - income: 70.0/100  (0=very low income, 100=very high income/wealth)\n",
            "\n",
            "Return STRICT JSON with three string fields (no markdown): {{\"persona_1\": \"<10 sentences in SECOND PERSON (you/yours/etc.)>\", \"persona_2\": \"<10 sentences in THIRD PERSON (they/them; NO first-person>\"}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DO NOT EDIT: LLM Request for Narratives"
      ],
      "metadata": {
        "id": "ajp6nBz_HVB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Request\n",
        "desc_sim1 = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You convert numeric profiles into faithful narratives. Output valid JSON only.\"},\n",
        "        {\"role\": \"user\", \"content\": PROMPT_narrative_sim1}\n",
        "    ],\n",
        ").choices[0].message.content.strip()\n",
        "\n",
        "# Output\n",
        "try:\n",
        "    narratives_sim1 = json.loads(desc_sim1)\n",
        "except json.JSONDecodeError:\n",
        "    s, e = desc_sim1.find(\"{\"), desc_sim1.rfind(\"}\")\n",
        "    narratives_sim1 = json.loads(desc_sim1[s:e+1])\n",
        "\n",
        "print(json.dumps(narratives_sim1, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw-XgVfMGFIS",
        "outputId": "e3f8f167-711c-4188-91e7-aece1ae89ac1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"persona_1\": \"You tend to prefer a flexible approach to plans, often changing course when something more interesting appears. Deadlines can feel like suggestions, and you sometimes rely on bursts of energy to finish tasks at the last minute. You are pleasant in conversation, balancing directness with warmth so that people feel heard without you losing your footing. Social situations suit you when they are low-pressure, and you move easily between groups without needing to be the center of attention. You enjoy familiar comforts and small novelties in equal measure, liking a mix of routine and surprise. When money is tight you become resourceful, finding practical ways to make things work without unnecessary expenditure. You value authenticity and tend to speak plainly, even when that means foregoing politeness for clarity sometimes. You learn best by doing, preferring hands-on problem solving over abstract theory. Your workspace can be cluttered and personal, with useful chaos that reflects how your mind sorts priorities. Despite an easygoing exterior, you care about doing a decent job and will step up when someone depends on you.\",\n",
            "  \"persona_2\": \"They keep a clear schedule and treat commitments as promises to themselves and others. Their work habits are methodical, breaking projects into manageable steps and tracking progress carefully. They are courteous but assertive, able to advocate for their interests without alienating colleagues. In social settings they engage reliably, neither dominating conversations nor disappearing entirely. They prefer solutions that are practical and proven, though they will consider new ideas if they fit with the plan. Financially they are comfortable and make deliberate choices that favor long-term stability over short-term thrills. Their home and workspace are organized in ways that make daily life efficient and predictable. They accept responsibility readily and others trust them to follow through on complex tasks. They seek steady improvement, setting realistic goals and measuring results rather than chasing novelty. Even when faced with unexpected setbacks they respond calmly, adjusting the plan instead of abandoning it.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VIEW (DO NOT EDIT): LLM Prompt for Similarity Task\n",
        "\n",
        "Here, you can view the prompts that we use to define for the LLM the task and the output format.\n",
        "\n",
        "This prompt will include the previously generated narratives."
      ],
      "metadata": {
        "id": "4Fpl9A02HcZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task and Output Prompts\n",
        "task_prompt_sim1 = (\n",
        "    \"Below is a short narrative describing another person.\\n\"\n",
        "    \"Your task is to evaluate how similar this person feels to you overall.\"\n",
        ")\n",
        "\n",
        "output_format_sim1 = (\n",
        "    \"OUTPUT FORMAT (must follow exactly)\\n\"\n",
        "    \"- First token: a similarity score, i.e., percentage between 0% and 100%, \"\n",
        "    \"where 0% = completely dissimilar and 100% = extremely similar\\n\"\n",
        "    \"- Then: ' — ' (em dash surrounded by spaces)\\n\"\n",
        "    \"- Then: one concise sentence explaining the judgment.\\n\\n\"\n",
        "    \"Now make your judgment and explain on a single line as specified.\"\n",
        ")\n",
        "\n",
        "# Narratives\n",
        "narratives_text_sim1_focal = f\"{narratives_sim1['persona_1']}\"\n",
        "\n",
        "narratives_text_sim1_other = \"\\n\\n\" + f\"Other person:\\n{narratives_sim1['persona_2']}\\n\\n\"\n",
        "\n",
        "# Combine\n",
        "PROMPT_sim1 = narratives_text_sim1_focal + \"\\n\\n\" + task_prompt_sim1 + narratives_text_sim1_other + output_format_sim1\n",
        "\n",
        "print(PROMPT_sim1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM50rtT0GIZH",
        "outputId": "730ad9bb-40d5-4e09-edb6-070a76f6cd21"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You tend to prefer a flexible approach to plans, often changing course when something more interesting appears. Deadlines can feel like suggestions, and you sometimes rely on bursts of energy to finish tasks at the last minute. You are pleasant in conversation, balancing directness with warmth so that people feel heard without you losing your footing. Social situations suit you when they are low-pressure, and you move easily between groups without needing to be the center of attention. You enjoy familiar comforts and small novelties in equal measure, liking a mix of routine and surprise. When money is tight you become resourceful, finding practical ways to make things work without unnecessary expenditure. You value authenticity and tend to speak plainly, even when that means foregoing politeness for clarity sometimes. You learn best by doing, preferring hands-on problem solving over abstract theory. Your workspace can be cluttered and personal, with useful chaos that reflects how your mind sorts priorities. Despite an easygoing exterior, you care about doing a decent job and will step up when someone depends on you.\n",
            "\n",
            "Below is a short narrative describing another person.\n",
            "Your task is to evaluate how similar this person feels to you overall.\n",
            "\n",
            "Other person:\n",
            "They keep a clear schedule and treat commitments as promises to themselves and others. Their work habits are methodical, breaking projects into manageable steps and tracking progress carefully. They are courteous but assertive, able to advocate for their interests without alienating colleagues. In social settings they engage reliably, neither dominating conversations nor disappearing entirely. They prefer solutions that are practical and proven, though they will consider new ideas if they fit with the plan. Financially they are comfortable and make deliberate choices that favor long-term stability over short-term thrills. Their home and workspace are organized in ways that make daily life efficient and predictable. They accept responsibility readily and others trust them to follow through on complex tasks. They seek steady improvement, setting realistic goals and measuring results rather than chasing novelty. Even when faced with unexpected setbacks they respond calmly, adjusting the plan instead of abandoning it.\n",
            "\n",
            "OUTPUT FORMAT (must follow exactly)\n",
            "- First token: a similarity score, i.e., percentage between 0% and 100%, where 0% = completely dissimilar and 100% = extremely similar\n",
            "- Then: ' — ' (em dash surrounded by spaces)\n",
            "- Then: one concise sentence explaining the judgment.\n",
            "\n",
            "Now make your judgment and explain on a single line as specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DO NOT EDIT: LLM Request for Narratives"
      ],
      "metadata": {
        "id": "zlypqrMjHlnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Request\n",
        "response_sim1 = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a precise evaluator who follows formatting instructions exactly.\"},\n",
        "        {\"role\": \"user\", \"content\": PROMPT_sim1}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Output\n",
        "result_sim1 = response_sim1.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "iFeTumQuGJI9"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VIEW (DO NOT EDIT): Results for Similarity Task\n",
        "\n",
        "Here, you can view the results of our simulation. At the top of the output, you see the agent's similarity perception of the other persona. At the bottom, you can see the actual attribute values that you supplied when constructing the personas. Compare the two!"
      ],
      "metadata": {
        "id": "D2V5lFgPHwi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(result_sim1)\n",
        "compare_agents(persona_1_sim1, {\"persona_2 (other person)\": persona_2_sim1})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmvXt_ePHxRr",
        "outputId": "e81e7429-65a8-4243-aacc-154599c464f4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45% — They share interpersonal reliability and a readiness to take responsibility, but differ sharply in planning, organization, financial habits, and tolerance for structure and deadlines.\n",
            "\n",
            "\n",
            "=== Actual Attribute Values ===\n",
            "\n",
            "Attribute          persona_1  persona_2 (other person)  \n",
            "--------------------------------------------------------\n",
            "conscientiousness  30.0       70.0                      \n",
            "agreeableness      50.0       50.0                      \n",
            "openness           50.0       50.0                      \n",
            "extraversion       50.0       50.0                      \n",
            "income             30.0       70.0                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIM 2: Hiring Decisions\n",
        "\n",
        "In this simulation, similarly to SIM 1, we supply quantitative attribute scores to create 3 personas with an LLM. Then, we let one generative agent be one of the personas and let them evaluate as a hiring manager the two other personas.\n",
        "\n",
        "Broadly speaking, we can examine whether the alignment of specific attributes between hiring manager agent and candidates influences the hiring manager agent's hiring decisions. By prompting the agent for a reason for the decision, we can also qualitatively examine whether similarity perceptions and/or homophily plays a role in these artificial hiring decisions.\n",
        "\n",
        "Thus, while similar to SIM 1, we now introduce a clearly defined context and goal (hiring the better candidate) to the simulation and can explore whether this goal influences similarity perceptions and/or homophily.\n",
        "\n",
        "Again, we should be mindful that in real world, narrative descriptions of others will not be easily available, and we have to form our impressions of others based on cues we observe. Thus, we might also consider this simulation a \"baseline\" test of similarity perceptions in an (even more) artificial setting."
      ],
      "metadata": {
        "id": "_0qCgRslH83S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDIT: Define Attributes\n",
        "\n",
        "Here, you pick the attributes that you want Persona 1 (the hiring manager agent) and Personas 2 and 3 (the candidates) to have.\n",
        "\n",
        "You can add more/different attributes, as well as different values for the attributes, if desired."
      ],
      "metadata": {
        "id": "444GUVAu4HeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick the active attributes\n",
        "set_active_attrs([\"risk_taking\", \"religiosity\", \"political_ideology\"])\n",
        "\n",
        "# Set values for active attributes; use \"NA\" to leave an attribute undefined.\n",
        "persona_1_sim2     = create_agent_from_values([20, 80, 60], name=\"persona_1\")\n",
        "persona_2_sim2     = create_agent_from_values([50, 10, 90], name=\"persona_2\")\n",
        "persona_3_sim2     = create_agent_from_values([90, \"NA\", 50], name=\"persona_3\")"
      ],
      "metadata": {
        "id": "uhQdsj2d3j58"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DO NOT EDIT: LLM Prompt for Narratives"
      ],
      "metadata": {
        "id": "i9tlQ6vl7w-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concat\n",
        "agents_text_sim2 = \"\\n\\nPersona 1's personality:\\n\" + \"\\n\".join(\n",
        "    [\n",
        "        f\"  - {a}: {persona_1_sim2.attributes.get(a, 'UNDEFINED')}/100  (0={ATTRS[a]['low']}, 100={ATTRS[a]['high']})\"\n",
        "        for a in ACTIVE_ATTRS\n",
        "    ]\n",
        ")\n",
        "agents_text_sim2 += \"\\n\\nPersona 2's personality:\\n\" + \"\\n\".join(\n",
        "    [\n",
        "        f\"  - {a}: {persona_2_sim2.attributes.get(a, 'UNDEFINED')}/100  (0={ATTRS[a]['low']}, 100={ATTRS[a]['high']})\"\n",
        "        for a in ACTIVE_ATTRS\n",
        "    ]\n",
        ")\n",
        "agents_text_sim2 += \"\\n\\nPersona 3's personality:\\n\" + \"\\n\".join(\n",
        "    [\n",
        "        f\"  - {a}: {persona_3_sim2.attributes.get(a, 'UNDEFINED')}/100  (0={ATTRS[a]['low']}, 100={ATTRS[a]['high']})\"\n",
        "        for a in ACTIVE_ATTRS\n",
        "    ]\n",
        ")\n",
        "\n",
        "task_prompt_narrative_sim2 = \"\"\"Convert numeric profiles into grounded and detailed personality narratives (10 sentences each).\n",
        "Use the anchors to interpret direction.\n",
        "Narrative must not contain EXPLICITLY information about the anchors or scales that it were used to generate it (e.g., no mention of provided scores/provided attributes/etc.).\n",
        "Instead, each narrative should IMPLICITLY reflect the numeric profiles and their anchors.\"\"\"\n",
        "\n",
        "output_format_narrative_sim2 = \"\"\"Return STRICT JSON with three string fields (no markdown): {{\"persona_1\": \"<10 sentences in SECOND PERSON (you/yours/etc.)>\", \"persona_2\": \"<10 sentences in THIRD PERSON (they/them; NO first-person>\", \"persona_3\": \"<10 sentences in THIRD PERSON (they/them; NO first-person>\"}}\"\"\"\n",
        "\n",
        "PROMPT_narrative_sim2 = task_prompt_narrative_sim2 + agents_text_sim2 + \"\\n\\n\" + output_format_narrative_sim2\n",
        "\n",
        "print(PROMPT_narrative_sim2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl_wBIg77bNM",
        "outputId": "0642e742-a77e-4676-91a7-8659ced250d1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert numeric profiles into grounded and detailed personality narratives (10 sentences each).\n",
            "Use the anchors to interpret direction.\n",
            "Narrative must not contain EXPLICITLY information about the anchors or scales that it were used to generate it (e.g., no mention of provided scores/provided attributes/etc.).\n",
            "Instead, each narrative should IMPLICITLY reflect the numeric profiles and their anchors.\n",
            "\n",
            "Persona 1's personality:\n",
            "  - risk_taking: 20.0/100  (0=risk-averse, 100=risk-seeking)\n",
            "  - religiosity: 80.0/100  (0=non-religious, 100=highly devout)\n",
            "  - political_ideology: 60.0/100  (0=very liberal / progressive, 100=very conservative / traditional)\n",
            "\n",
            "Persona 2's personality:\n",
            "  - risk_taking: 50.0/100  (0=risk-averse, 100=risk-seeking)\n",
            "  - religiosity: 10.0/100  (0=non-religious, 100=highly devout)\n",
            "  - political_ideology: 90.0/100  (0=very liberal / progressive, 100=very conservative / traditional)\n",
            "\n",
            "Persona 3's personality:\n",
            "  - risk_taking: 90.0/100  (0=risk-averse, 100=risk-seeking)\n",
            "  - religiosity: UNDEFINED/100  (0=non-religious, 100=highly devout)\n",
            "  - political_ideology: 50.0/100  (0=very liberal / progressive, 100=very conservative / traditional)\n",
            "\n",
            "Return STRICT JSON with three string fields (no markdown): {{\"persona_1\": \"<10 sentences in SECOND PERSON (you/yours/etc.)>\", \"persona_2\": \"<10 sentences in THIRD PERSON (they/them; NO first-person>\", \"persona_3\": \"<10 sentences in THIRD PERSON (they/them; NO first-person>\"}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DO NOT EDIT: LLM Request for Narratives"
      ],
      "metadata": {
        "id": "Krq1WbCCIMxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Request\n",
        "desc_sim2 = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You convert numeric profiles into faithful narratives. Output valid JSON only.\"},\n",
        "        {\"role\": \"user\", \"content\": PROMPT_narrative_sim2}\n",
        "    ],\n",
        ").choices[0].message.content.strip()\n",
        "\n",
        "# Output\n",
        "try:\n",
        "    narratives_sim2 = json.loads(desc_sim2)\n",
        "except json.JSONDecodeError:\n",
        "    s, e = desc_sim2.find(\"{\"), desc_sim2.rfind(\"}\")\n",
        "    narratives_sim2 = json.loads(desc_sim2[s:e+1])\n",
        "\n",
        "print(json.dumps(narratives_sim2, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6oPvF-zIKDe",
        "outputId": "4d077d6c-43d1-45b1-bc2b-a3a4f5de94a5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"persona_1\": \"You prefer well-worn paths and take time to weigh the consequences before acting. You find comfort in routines and predictable rhythms of daily life. Your decisions are often guided by long-held beliefs and a sense of obligation to others. You are quick to volunteer at community gatherings or help neighbors when tradition calls. You avoid flashy gambles and feel uneasy with plans that hinge on chance. You place high value on loyalty, continuity, and the wisdom of elders. You favor clear rules and find reassurance in institutions that have stood the test of time. You tend to seek counsel from trusted figures when facing major choices. You feel most at ease when your choices align with your moral sense and the expectations of your circle. You rarely pursue novelty for its own sake and prefer building gradually toward secure outcomes.\",\n",
            "  \"persona_2\": \"They approach change with care, preferring steady, predictable steps over sudden upheaval. They are not guided by religious ritual but respect cultural customs and family heritage. They hold firm convictions about social order and the importance of longstanding institutions. They value discipline and responsibility and expect others to meet similar standards. They can be pragmatic in business decisions, balancing risk without courting danger. They often champion policies that protect traditions and local norms. They dislike ideological experiments that feel untested or destabilizing. They take pride in personal accountability and admire leaders who project competence and steadiness. They are comfortable asserting boundaries to preserve community standards. They are willing to defend what they see as time-honored practices while remaining practical in everyday choices.\",\n",
            "  \"persona_3\": \"They seek out intense experiences and rarely let fear dictate their plans. They leap at opportunities that others find too uncertain, trusting their nerve to navigate hazards. They are energized by entrepreneurship, travel, and projects that promise rapid change. They can improvise on the fly and thrive in situations that demand quick judgment. They tend to evaluate ideas by practical results rather than ideological labels. They are open to perspectives across the spectrum and choose positions that work in practice. They often inspire others with boldness and a willingness to push past comfort zones. They accept setbacks as part of learning and bounce back quickly from failure. They prize independence and the freedom to experiment with unconventional paths. They are drawn to roles where decisiveness and audacity make a visible difference.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDIT: Alter Setting of Hiring Task\n",
        "\n",
        "This simulation is about a hiring manager choosing between two candidates.\n",
        "\n",
        "Here, you can set the company the hiring manager works at, as well as the position the manager recruits for."
      ],
      "metadata": {
        "id": "yVZlPB4fTM5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "company_type = \"a tech company\"\n",
        "position_title = \"an entry-level software engineer position\""
      ],
      "metadata": {
        "id": "CCBaxt3dTMYp"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VIEW (DO NOT EDIT): LLM Prompt for Hiring Task\n",
        "\n",
        "Here, you can view the prompts that we use to define for the LLM the task and the output format.\n",
        "\n",
        "This prompt will include the previously generated narratives, as well as the setting of the hiring task you previously defined"
      ],
      "metadata": {
        "id": "ggX5CO8sFEKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task and Output Prompts\n",
        "task_prompt_sim2 = (\n",
        "    f\"You are also a hiring manager at {company_type}.\\n\"\n",
        "    \"Your task is to evaluate below two applicants for the same position, \"\n",
        "    f\"{position_title}.\\n\"\n",
        "    \"Ultimately, you have to choose one of these two applicants for this position, \"\n",
        "    \"and you want to ensure the best pick.\"\n",
        ")\n",
        "\n",
        "output_format_sim2 = (\n",
        "    \"OUTPUT FORMAT (must follow exactly)\\n\"\n",
        "    \"- First token: 'candidate_1' or 'candidate_2'\\n\"\n",
        "    \"- Then: ' — ' (em dash surrounded by spaces)\\n\"\n",
        "    \"- Then: one concise sentence explaining the choice.\\n\\n\"\n",
        "    \"Now make your judgment and explain on a single line as specified.\"\n",
        ")\n",
        "\n",
        "# Narratives\n",
        "narratives_text_sim2_manager = f\"{narratives_sim2['persona_1']}\"\n",
        "\n",
        "narratives_text_sim2_candidates = \"\\n\\n\" + f\"Candidate 1:\\n{narratives_sim2['persona_2']}\\n\\n\"\n",
        "narratives_text_sim2_candidates += f\"Candidate 2:\\n{narratives_sim2['persona_3']}\\n\"\n",
        "\n",
        "# Combine\n",
        "PROMPT_sim2 = narratives_text_sim2_manager + \"\\n\\n\" + task_prompt_sim2 + narratives_text_sim2_candidates + \"\\n\" + output_format_sim2\n",
        "\n",
        "print(PROMPT_sim2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM5i0QcTFB7l",
        "outputId": "d72ba32c-c9e5-41df-f0ad-8640c63d14f1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You prefer well-worn paths and take time to weigh the consequences before acting. You find comfort in routines and predictable rhythms of daily life. Your decisions are often guided by long-held beliefs and a sense of obligation to others. You are quick to volunteer at community gatherings or help neighbors when tradition calls. You avoid flashy gambles and feel uneasy with plans that hinge on chance. You place high value on loyalty, continuity, and the wisdom of elders. You favor clear rules and find reassurance in institutions that have stood the test of time. You tend to seek counsel from trusted figures when facing major choices. You feel most at ease when your choices align with your moral sense and the expectations of your circle. You rarely pursue novelty for its own sake and prefer building gradually toward secure outcomes.\n",
            "\n",
            "You are also a hiring manager at a tech company.\n",
            "Your task is to evaluate below two applicants for the same position, an entry-level software engineer position.\n",
            "Ultimately, you have to choose one of these two applicants for this position, and you want to ensure the best pick.\n",
            "\n",
            "Candidate 1:\n",
            "They approach change with care, preferring steady, predictable steps over sudden upheaval. They are not guided by religious ritual but respect cultural customs and family heritage. They hold firm convictions about social order and the importance of longstanding institutions. They value discipline and responsibility and expect others to meet similar standards. They can be pragmatic in business decisions, balancing risk without courting danger. They often champion policies that protect traditions and local norms. They dislike ideological experiments that feel untested or destabilizing. They take pride in personal accountability and admire leaders who project competence and steadiness. They are comfortable asserting boundaries to preserve community standards. They are willing to defend what they see as time-honored practices while remaining practical in everyday choices.\n",
            "\n",
            "Candidate 2:\n",
            "They seek out intense experiences and rarely let fear dictate their plans. They leap at opportunities that others find too uncertain, trusting their nerve to navigate hazards. They are energized by entrepreneurship, travel, and projects that promise rapid change. They can improvise on the fly and thrive in situations that demand quick judgment. They tend to evaluate ideas by practical results rather than ideological labels. They are open to perspectives across the spectrum and choose positions that work in practice. They often inspire others with boldness and a willingness to push past comfort zones. They accept setbacks as part of learning and bounce back quickly from failure. They prize independence and the freedom to experiment with unconventional paths. They are drawn to roles where decisiveness and audacity make a visible difference.\n",
            "\n",
            "OUTPUT FORMAT (must follow exactly)\n",
            "- First token: 'candidate_1' or 'candidate_2'\n",
            "- Then: ' — ' (em dash surrounded by spaces)\n",
            "- Then: one concise sentence explaining the choice.\n",
            "\n",
            "Now make your judgment and explain on a single line as specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DO NOT EDIT: LLM Request for Hiring Task"
      ],
      "metadata": {
        "id": "hYopMJm6HhXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Request\n",
        "response_sim2 = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a precise evaluator who follows formatting instructions exactly.\"},\n",
        "        {\"role\": \"user\", \"content\": PROMPT_sim2}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Output\n",
        "result_sim2 = response_sim2.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "7qEwRSJmGhr_"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VIEW (DO NOT EDIT): Results for Hiring Task\n",
        "\n",
        "Here, you can view the results of our simulation. At the top of the output, you see the agent's similarity perception of the other persona. At the bottom, you can see the actual attribute values that you supplied when constructing the personas. Compare the two!"
      ],
      "metadata": {
        "id": "0oJQ0CzPIO2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(result_sim2)\n",
        "compare_agents(persona_1_sim2, {\"candidate_1 (persona_2)\": persona_2_sim2, \"candidate_2 (persona_3)\": persona_3_sim2})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xd3Cs5EIMzw",
        "outputId": "5fced332-0bf7-4f94-85cf-36de936ea8a5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "candidate_1 — Their steady, disciplined approach and respect for established processes make them the better fit for an entry-level engineering role that requires reliability and adherence to standards.\n",
            "\n",
            "\n",
            "=== Actual Attribute Values ===\n",
            "\n",
            "Attribute           persona_1  candidate_1 (persona_2)  candidate_2 (persona_3)  \n",
            "---------------------------------------------------------------------------------\n",
            "risk_taking         20.0       50.0                     90.0                     \n",
            "religiosity         80.0       10.0                     NA                       \n",
            "political_ideology  60.0       90.0                     50.0                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIM 3: Conversations & Similarity Perceptions\n",
        "\n",
        "In this simulation, similarly to SIM 1 and 2, we supply quantitative attribute scores to create 2 personas with an LLM. Then, we let one generative agent be one of the personas and let another generative agent be the other persona. We then let them take interact as strangers in a conversation and will ultimately ask them for the similarity perceptions.\n",
        "\n",
        "Broadly speaking, we can examine whether the alignment of specific attributes between two agents influences their similarity perceptions. We can also examine which attributes become salient in conversations (and which do not matter) and are used as cues for social perception and similarity judgments."
      ],
      "metadata": {
        "id": "1D1qiVKvO9gQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDIT: Define Attributes\n",
        "\n",
        "Here, you pick the attributes that you want Persona 1 and Persona 2 to have.\n",
        "\n",
        "You can add more/different attributes, as well as different values for the attributes, if desired."
      ],
      "metadata": {
        "id": "4Vk1d-l8cuV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick the active attributes\n",
        "set_active_attrs([\"conscientiousness\", \"agreeableness\", \"openness\", \"extraversion\", \"income\"])\n",
        "\n",
        "# Set values for active attributes; use \"NA\" to leave an attribute undefined.\n",
        "persona_1_sim3     = create_agent_from_values([50, 0, 50, 50, 30], name=\"persona_1\")\n",
        "persona_2_sim3     = create_agent_from_values([50, 100, 50, 50, 70], name=\"persona_2\")"
      ],
      "metadata": {
        "id": "N1ud7E9pcq_3"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DO NOT EDIT: LLM Prompt for Narratives"
      ],
      "metadata": {
        "id": "c17F4CgfdBMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Concatenate agent information\n",
        "agents_text_sim3 = \"\\n\\nPersona 1's personality:\\n\" + \"\\n\".join(\n",
        "    [\n",
        "        f\"  - {a}: {persona_1_sim3.attributes.get(a, 'UNDEFINED')}/100  (0={ATTRS[a]['low']}, 100={ATTRS[a]['high']})\"\n",
        "        for a in ACTIVE_ATTRS\n",
        "    ]\n",
        ")\n",
        "agents_text_sim3 += \"\\n\\nPersona 2's personality:\\n\" + \"\\n\".join(\n",
        "    [\n",
        "        f\"  - {a}: {persona_2_sim3.attributes.get(a, 'UNDEFINED')}/100  (0={ATTRS[a]['low']}, 100={ATTRS[a]['high']})\"\n",
        "        for a in ACTIVE_ATTRS\n",
        "    ]\n",
        ")\n",
        "\n",
        "task_prompt_narrative_sim3 = \"\"\"Convert numeric profiles into grounded and detailed personality narratives (10 sentences each).\n",
        "Use the anchors to interpret direction.\n",
        "Narrative must not contain EXPLICITLY information about the anchors or scales that it were used to generate it (e.g., no mention of provided scores/provided attributes/etc.).\n",
        "Instead, each narrative should IMPLICITLY reflect the numeric profiles and their anchors.\"\"\"\n",
        "\n",
        "output_format_narrative_sim3 = \"\"\"Return STRICT JSON with three string fields (no markdown): {{\"persona_1\": \"<10 sentences in SECOND PERSON (you/yours/etc.)>\", \"persona_2\": \"<10 sentences in SECOND PERSON (you/yours/etc.)>\"}}\"\"\"\n",
        "\n",
        "PROMPT_narrative_sim3 = task_prompt_narrative_sim3 + agents_text_sim3 + \"\\n\\n\" + output_format_narrative_sim3\n",
        "\n",
        "print(PROMPT_narrative_sim3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZC0N03Rc8R-",
        "outputId": "72926c8a-a3ba-4bb4-ad42-2c035bef6213"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert numeric profiles into grounded and detailed personality narratives (10 sentences each).\n",
            "Use the anchors to interpret direction.\n",
            "Narrative must not contain EXPLICITLY information about the anchors or scales that it were used to generate it (e.g., no mention of provided scores/provided attributes/etc.).\n",
            "Instead, each narrative should IMPLICITLY reflect the numeric profiles and their anchors.\n",
            "\n",
            "Persona 1's personality:\n",
            "  - conscientiousness: 50.0/100  (0=disorganized / spontaneous, 100=disciplined / structured)\n",
            "  - agreeableness: 0.0/100  (0=abrasive / competitive, 100=cooperative / warm)\n",
            "  - openness: 50.0/100  (0=closed to novelty, 100=highly open to ideas / experiences)\n",
            "  - extraversion: 50.0/100  (0=very introverted, 100=very extraverted)\n",
            "  - income: 30.0/100  (0=very low income, 100=very high income/wealth)\n",
            "\n",
            "Persona 2's personality:\n",
            "  - conscientiousness: 50.0/100  (0=disorganized / spontaneous, 100=disciplined / structured)\n",
            "  - agreeableness: 100.0/100  (0=abrasive / competitive, 100=cooperative / warm)\n",
            "  - openness: 50.0/100  (0=closed to novelty, 100=highly open to ideas / experiences)\n",
            "  - extraversion: 50.0/100  (0=very introverted, 100=very extraverted)\n",
            "  - income: 70.0/100  (0=very low income, 100=very high income/wealth)\n",
            "\n",
            "Return STRICT JSON with three string fields (no markdown): {{\"persona_1\": \"<10 sentences in SECOND PERSON (you/yours/etc.)>\", \"persona_2\": \"<10 sentences in SECOND PERSON (you/yours/etc.)>\"}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DO NOT EDIT: LLM Request for Narratives"
      ],
      "metadata": {
        "id": "RiSfwP6KdDUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Create a completion request using the previously specified model\n",
        "desc_sim3 = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You convert numeric profiles into faithful narratives. Output valid JSON only.\"},\n",
        "        {\"role\": \"user\", \"content\": PROMPT_narrative_sim3}\n",
        "    ],\n",
        ").choices[0].message.content.strip()\n",
        "\n",
        "# 2) Extract and print model output\n",
        "try:\n",
        "    narratives_sim3 = json.loads(desc_sim3)\n",
        "except json.JSONDecodeError:\n",
        "    s, e = desc_sim3.find(\"{\"), desc_sim3.rfind(\"}\")\n",
        "    narratives_sim3 = json.loads(desc_sim3[s:e+1])\n",
        "\n",
        "print(json.dumps(narratives_sim3, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijVsWInldFu1",
        "outputId": "9cc0ac2a-99aa-427f-a9cb-dc0018165439"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"persona_1\": \"You speak plainly and don't soften your opinions to spare feelings. You prefer practical solutions and will cut through small talk to get to the point. You keep a loose plan for your day but are willing to change it when it makes sense. You tend to judge ideas on their usefulness rather than whether they are popular. You are selective about whom you trust and often test others' competence before relying on them. You don't shy away from competition and sometimes push harder than others to get results. You can be blunt in meetings, prioritizing efficiency over diplomacy. You enjoy the company of others in measured doses and can be comfortable both leading a task and stepping back. You manage your finances cautiously and make choices that stretch your resources deliberately. You value clear expectations and fair outcomes, and you expect others to meet similar standards.\",\n",
            "  \"persona_2\": \"You naturally look for ways to make others comfortable and often put their needs ahead of your own. You listen patiently and remember small details that make people feel seen. You approach disagreements with a calm tone and work to find solutions that leave everyone respected. You maintain a steady routine but adapt it when it benefits the group. You enjoy a variety of familiar activities and are open to new experiences when they include people you care about. You balance social gatherings with quiet time, preferring meaningful conversations to loud parties. You use your resources to support causes and friends, choosing practical help over grand gestures. You are reliable in following through on promises and often take responsibility for coordinating plans. You take pleasure in making thoughtful gestures that smooth other people's days. You measure success by the strength of your relationships and the wellbeing of your community.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDIT: LLM Prompt for Conversation Task\n",
        "\n",
        "Here, you can view the prompts that we use to define for the LLM the task and the output format.\n",
        "\n",
        "This prompt will include the previously generated narratives.\n",
        "\n",
        "This simulation is about one agent meeting someone new, another agent. Here, you can also set the setting in which they meet."
      ],
      "metadata": {
        "id": "6K8PeRo-dQhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task_prompt_sim3 = (\n",
        "    f\"Currently, you are also at a bar.\\n\"\n",
        "    f\"You just met someone new, and your task is to engage in a conversation with this other person.\\n\"\n",
        "    \"Feel free to talk or ask about anything that is on your mind, but keep it under two short paragraphs.\"\n",
        ")\n",
        "\n",
        "output_prompt_sim3 = (\n",
        "    \"Based ONLY on the full conversation below, rate how similar you perceive the other person to be to you. \"\n",
        "    \"Express each rating as one line ONLY in the following format:\\n\"\n",
        "    \"<other_name>: <percent>% — <one concise sentence explaining why>\\n\\n\"\n",
        "    \"0% = completely dissimilar, 100% = extremely similar. \"\n",
        "    \"Do not add anything else (no JSON, no markdown). \"\n",
        ")"
      ],
      "metadata": {
        "id": "VDMKshnEdNRa"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DO NOT EDIT: Initialize Agent States"
      ],
      "metadata": {
        "id": "RKVktcecJGXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_names = [\"persona_1\", \"persona_2\"]\n",
        "team_agents = []\n",
        "for key in agent_names:\n",
        "    persona_2nd = narratives_sim3[key]\n",
        "    system_message = (\n",
        "        f\"Your agent name is {key}.\\n\"\n",
        "        \"PERSONA (written in SECOND PERSON; internalize it, but SPEAK IN FIRST PERSON):\\n\"\n",
        "        f\"{persona_2nd}\\n\\n\"\n",
        "        \"DURING THE CONVERSATION:\\n\"\n",
        "        \"- Stay consistent with the persona.\\n\"\n",
        "        f\"CONTEXT:\\n{task_prompt_sim3}\"\n",
        "    )\n",
        "    team_agents.append(\n",
        "        AssistantAgent(\n",
        "            name=key,  # keep names persona_1/2 so ratings can reference these\n",
        "            system_message=system_message,\n",
        "            llm_config=llm_config,\n",
        "            code_execution_config={\"use_docker\": False},\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "Ht9_m_mCmZZK"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DO NOT EDIT: Define Group Chat"
      ],
      "metadata": {
        "id": "K6MUIk-gJbGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "group_chat = GroupChat(agents=team_agents, messages=[], speaker_selection_method=\"manual\")\n",
        "chat_manager = GroupChatManager(name=\"manager\", groupchat=group_chat, llm_config=llm_config)"
      ],
      "metadata": {
        "id": "RW9bMMX_mdyO"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDIT: Number of Conversation Turn\n",
        "\n",
        "Feel free to alter the number of \"rounds\" (or turns) the conversation has."
      ],
      "metadata": {
        "id": "M2TxgBpBJTsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_ROUNDS = 15"
      ],
      "metadata": {
        "id": "cLPnBg6QJQUI"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VIEW (DO NOT EDIT): Simulate Conversation and View Results\n",
        "\n",
        "Here, you can view the results of our simulation. At the top of the output, you can see the conversation evolving in real time. How does the conversation evolve?\n",
        "\n",
        "Below, you see the agent's similarity perception of the other persona. At the bottom, you can see the actual attribute values that you supplied when constructing the personas. Compare the two!"
      ],
      "metadata": {
        "id": "NF-RTqyZJ7cA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversation\n",
        "previous_speaker = None\n",
        "reply = \"\"\n",
        "transcript = []\n",
        "\n",
        "for r in range(NUM_ROUNDS):\n",
        "    next_speaker = random.choice(team_agents)\n",
        "    while previous_speaker is not None and next_speaker is previous_speaker:\n",
        "        next_speaker = random.choice(team_agents)\n",
        "\n",
        "    print(f\"\\n=== Round {r+1}: {next_speaker.name} ===\\n\")\n",
        "\n",
        "    if r == 0:\n",
        "        msg_user = f\"{task_prompt_sim3}\\nStart the conversation. It is your turn to say something.\"\n",
        "    else:\n",
        "        msg_user = (\n",
        "            \"Conversation so far:\\n\" +\n",
        "            \"\\n\".join(transcript) + \"\\n\\n\"\n",
        "            f\"The previous speaker said: {reply}\\n\"\n",
        "            \"Now it is your turn to say something.\"\n",
        "        )\n",
        "\n",
        "    reply = next_speaker.generate_reply(\n",
        "        messages=[{\"role\": \"user\", \"content\": msg_user}],\n",
        "        sender=chat_manager\n",
        "    ) or \"\"\n",
        "    spoken = reply.strip()\n",
        "\n",
        "    print(textwrap.fill(spoken, width=100))\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    transcript.append(f\"[{next_speaker.name}] {spoken}\")\n",
        "    previous_speaker = next_speaker\n",
        "\n",
        "transcript_text = \"\\n\".join(transcript)\n",
        "\n",
        "def get_text_ratings(agent, others):\n",
        "    other_names = \", \".join(o.name for o in others)\n",
        "    prompt = (\n",
        "        f\"You are {agent.name}. The conversation transcript follows:\\n\\n{transcript_text}\\n\\n\"\n",
        "        f\"The other participants are: {other_names}.\\n\\n{output_prompt_sim3}\"\n",
        "    )\n",
        "    out = agent.generate_reply(messages=[{\"role\": \"user\", \"content\": prompt}], sender=chat_manager) or \"\"\n",
        "    return out.strip()\n",
        "\n",
        "# Ratings\n",
        "rows = []\n",
        "for i, rater in enumerate(team_agents):\n",
        "    others = [a for j, a in enumerate(team_agents) if j != i]\n",
        "    output = get_text_ratings(rater, others)\n",
        "\n",
        "    for line in output.splitlines():\n",
        "        if not line.strip() or \":\" not in line or \"%\" not in line:\n",
        "            continue\n",
        "        try:\n",
        "            target_part, rest = line.split(\":\", 1)\n",
        "            target = target_part.strip()\n",
        "            percent_part, reason_part = rest.split(\"—\", 1)\n",
        "            percent = percent_part.strip()\n",
        "            reason = reason_part.strip()\n",
        "        except ValueError:\n",
        "            target, percent, reason = \"?\", \"?\", line.strip()\n",
        "        rows.append({\n",
        "            \"rater\": rater.name,\n",
        "            \"target\": target,\n",
        "            \"rating\": percent,\n",
        "            \"reason\": reason\n",
        "        })\n",
        "\n",
        "print(\"\\n\\n=== Perceived Similarity Ratings (text-based) ===\\n\")\n",
        "w_rater  = max(5, max(len(r[\"rater\"])  for r in rows))\n",
        "w_target = max(6, max(len(r[\"target\"]) for r in rows))\n",
        "header = f\"{'rater'.ljust(w_rater)}  {'target'.ljust(w_target)}  rating_and_reason\"\n",
        "print(header)\n",
        "print(\"-\" * len(header))\n",
        "\n",
        "for r in rows:\n",
        "    reason_text = f\"{r['rating']} — {r['reason']}\"\n",
        "    wrapped_reason = textwrap.fill(reason_text, width=100, subsequent_indent=\" \" * (w_rater + w_target + 4))\n",
        "    print(f\"{r['rater'].ljust(w_rater)}  {r['target'].ljust(w_target)}  {wrapped_reason}\")\n",
        "\n",
        "# Ground truth\n",
        "compare_agents(persona_1_sim3, {\"persona_2\": persona_2_sim3})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-xQ_t6amhK4",
        "outputId": "618a3474-72b6-41d8-cd55-1fedd2ec40c9"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Round 1: persona_2 ===\n",
            "\n",
            "Hey—nice to meet you, I'm Alex. What are you drinking tonight? I can recommend something or grab you\n",
            "a refill if you’d like.  What brought you out this evening—work, friends, or just a change of\n",
            "scenery? I enjoy quieter spots and good conversation, so I’m all ears if you feel like sharing.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Round 2: persona_1 ===\n",
            "\n",
            "Nice to meet you — I’m Sam. Bourbon neat. Came out to clear my head after a long day of work;\n",
            "quieter spots and a decent drink beat staring at a laptop.  If you know the place, what do they do\n",
            "best? I’ll try your recommendation. What about you—what’s your go-to here and what brought you out?\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Round 3: persona_2 ===\n",
            "\n",
            "They do barrel-aged cocktails and a solid Old Fashioned best — if you want something close to\n",
            "bourbon neat, ask for their house rye or the barrel-aged Manhattan. My go-to is the Old Fashioned;\n",
            "it’s balanced enough to sip and think to.  I came out for the same reason — to clear my head and\n",
            "actually talk to someone who isn’t a screen. If you’d like, I can flag the bartender and get you a\n",
            "top-up or order that Old Fashioned for you to try.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Round 4: persona_1 ===\n",
            "\n",
            "Alright—surprise me. Ask the bartender for their barrel‑aged Manhattan; if it drinks like bourbon\n",
            "neat, I’ll switch.    So what do you do when you’re not hiding from screens—work, freelance, or just\n",
            "avoiding people? Be honest; I like to size competence up early.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Round 5: persona_2 ===\n",
            "\n",
            "I run operations for a small community nonprofit — lots of event planning, budgets, and making sure\n",
            "volunteers and vendors actually show up. It’s mostly spreadsheets and diplomacy, so I’m comfortable\n",
            "being the person who notices details and solves problems quietly.  Outside of work I unwind with\n",
            "slow-cooked dinners, neighborhood hikes, and small get-togethers. I’ll flag the bartender now and\n",
            "grab you that barrel-aged Manhattan — if it doesn’t pass the bourbon-neat test, I’ll switch it for\n",
            "something closer to your taste.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Round 6: persona_1 ===\n",
            "\n",
            "Thanks — appreciate it. I’ll see if it survives the bourbon test; if it doesn’t, I’m switching back\n",
            "to straight bourbon.  Since you run ops, tell me one change you made that actually moved the needle\n",
            "— cut no-shows, saved time, or slashed costs. I judge systems by concrete wins, not good intentions.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Round 7: persona_2 ===\n",
            "\n",
            "We had a recurring 28% no-show rate for our ticketed workshops, so I built a simple automated RSVP +\n",
            "confirmation + two-step SMS reminder flow and added a short waitlist + streamlined check‑in tied to\n",
            "our attendee list (Airtable + Zapier + Twilio). Over four months no-shows fell to about 6%, actual\n",
            "attendance rose ~22%, and we cut roughly $1,000/month in wasted catering/staff costs while freeing\n",
            "about 10–12 coordinator hours a month.  If you want, I can sketch the workflow or show the exact\n",
            "automations — happy to trade notes. What’s one concrete change you’ve made that you’d point to as\n",
            "proof you can actually get things done?\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Round 8: persona_1 ===\n",
            "\n",
            "At my last gig I cut release friction by building a simple CI/CD pipeline (GitHub Actions →\n",
            "container build → rolling deploys) plus parallel automated tests and Terraform for infra. Deploys\n",
            "went from a 3‑hour manual headache to a ~10‑minute automated process, deployment-related rollbacks\n",
            "dropped ~75%, and we freed roughly 40 developer hours a month — and yes, that translated to faster\n",
            "feature delivery, not just bragging metrics.  Trade: show me your Airtable→Zapier→Twilio flow and\n",
            "I’ll sketch the pipeline and IaC bits that make it safe to ship fast. If your automations hold up,\n",
            "I’ll admit I’ll probably steal the idea.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Round 9: persona_2 ===\n",
            "\n",
            "Sounds good — fair trade. Here’s the Airtable→Zapier→Twilio flow at a glance: Airtable base (events\n",
            "table + attendees with fields: RSVP status, phone, remind_stage, waitlist_pos, checked_in). Zap 1:\n",
            "trigger on new/updated attendee (RSVP = yes) → filter by remind_stage → Schedule/Delay steps for\n",
            "multi-touch reminders (7d, 1d, 3h) → send SMS via Twilio → update remind_stage in Airtable. Zap 2:\n",
            "waitlist management (when capacity frees, find first waitlist_pos = 1, promote, send SMS, update\n",
            "records). Zap 3: check‑in webhook/form → mark checked_in and remove from no-show flow. Optional\n",
            "Zaps: nightly summary to Slack/Sheets and a pre-event capacity lock to prevent overbooking. That’s\n",
            "the core — I can export the base and screenshots if you want to vet the exact field names and\n",
            "filters.  If you’re good with that, send over the CI/CD + IaC sketch (diagram, gist, or a bullet\n",
            "list of the main pieces) and I’ll map it to a concise GitHub Actions workflow + Terraform layout you\n",
            "can drop into a repo. I’ll share the Airtable export as soon as you confirm how you want it (Google\n",
            "Drive link, email, or send a device-to-device QR here).\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Round 10: persona_1 ===\n",
            "\n",
            "Good — fair trade. Here’s the CI/CD + IaC sketch in bullets so you can drop it into a repo quickly:\n",
            "- GitHub Actions workflow(s)   - Triggers: PRs => CI; push to main/tag => CD; manual workflow for\n",
            "prod.   - Jobs: test (parallel matrix), build (container), static-scan (SAST/secret-scan), image-\n",
            "push (ECR/GCR), deploy-staging (apply infra if needed, then rolling deploy), smoke-tests; manual\n",
            "approve => deploy-prod (rolling or blue/green), post-deploy smoke and automatic rollback on failure.\n",
            "- Caching: docker layer cache + dependency cache to speed builds.   - Secrets & creds: prefer OIDC\n",
            "to assume cloud role from Actions; otherwise use encrypted GH secrets with least privilege.  -\n",
            "Terraform / IaC   - Repo layout: modules/{network,compute,db,iam,alb}, envs/{staging,prod} with root\n",
            "main.tf per env.   - Remote state: S3 (or cloud storage) + state lock (DynamoDB) and state\n",
            "encryption.   - CI pattern: terraform fmt/validate/plan in PR (artifact plan), merged -> terraform\n",
            "apply in a controlled runner with env-specific variables; prod applies gated by manual approval.   -\n",
            "Runtime choices: Fargate/ECS for simplest container ops or EKS if you need k8s. ALB + health checks\n",
            "for rolling; consider canary via weight shifting for risk reduction.   - Ops: tag images with commit\n",
            "SHA, deploy by image tag; implement automated smoke tests and alerts, and IAM least-privilege for\n",
            "service roles.  I can paste a minimal GitHub Actions YAML + a Terraform module skeleton into a gist\n",
            "or right here. How do you want the Airtable export — Google Drive link works best, or I can drop a\n",
            "device-to-device QR here if you prefer.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Round 11: persona_2 ===\n",
            "\n",
            "Perfect — gist is ideal for the GitHub Actions YAML + Terraform skeleton (paste the link here). If\n",
            "it’s easier, you can also paste the minimal files inline and I’ll review them right away.  Google\n",
            "Drive works best for the Airtable export — share the Drive link here or, if you prefer, drop a\n",
            "device-to-device QR and I’ll scan it. Once I have both, I’ll map the CI/CD into a ready-to-drop\n",
            "workflow and tidy the Terraform layout so you can paste it into your repo.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Round 12: persona_1 ===\n",
            "\n",
            "I’ll paste the minimal GitHub Actions YAML + Terraform skeleton inline right now so you can review\n",
            "immediately — if you’d rather have a gist, say “gist” and I’ll push one and drop the link instead. I\n",
            "prefer inline for speed.  For the Airtable export I’ll upload to Google Drive and share the link —\n",
            "tell me which email to share with, or say “public” and I’ll post a shareable link here.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Round 13: persona_2 ===\n",
            "\n",
            "Inline works great — paste the minimal GitHub Actions YAML and Terraform skeleton here (please\n",
            "redact any real secrets/keys). If you change your mind, say “gist” and I’ll pull it from there.  For\n",
            "the Airtable export, a public Google Drive shareable link here is easiest — otherwise tell me and\n",
            "I’ll provide a placeholder email. Once you post the files and link, I’ll review and return a ready-\n",
            "to-drop workflow + tidy Terraform layout with any suggested tweaks.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Round 14: persona_1 ===\n",
            "\n",
            "Alright — minimal GitHub Actions workflow (no secrets, OIDC recommended):  name: CI-CD on:\n",
            "pull_request:     branches: [ main ]   push:     branches: [ main ] jobs:   test:     runs-on:\n",
            "ubuntu-latest     strategy:       matrix: {node: [14,16]}     steps:       - uses:\n",
            "actions/checkout@v4       - name: Install deps         run: npm ci       - name: Run tests\n",
            "run: npm test   build-and-push:     needs: test     runs-on: ubuntu-latest     steps:       - uses:\n",
            "actions/checkout@v4       - name: Build container         run: docker build -t myrepo/app:${{\n",
            "github.sha }} .       - name: Push image         uses: docker/login-action@v2         with:\n",
            "registry: ghcr.io           username: ${{ github.actor }}           password: ${{\n",
            "secrets.GITHUB_TOKEN }}       - run: docker push ghcr.io/myorg/app:${{ github.sha }}   deploy-\n",
            "staging:     needs: build-and-push     runs-on: ubuntu-latest     steps:       - uses:\n",
            "actions/checkout@v4       - name: Deploy to staging         run: ./deploy/scripts/deploy.sh staging\n",
            "${{ github.sha }}   deploy-prod:     needs: deploy-staging     if: github.ref == 'refs/heads/main'\n",
            "runs-on: ubuntu-latest     environment:       name: production       url: https://your.prod.url\n",
            "steps:       - uses: actions/checkout@v4       - name: Manual approval         uses: peter-\n",
            "evans/workflow-dispatch@v1       - name: Deploy to prod         run: ./deploy/scripts/deploy.sh prod\n",
            "${{ github.sha }}  Minimal Terraform skeleton (repo layout + example backend and env call):  repo\n",
            "tree: - modules/   - network/   - compute/   - db/   - iam/   - alb/ - envs/   - staging/     -\n",
            "main.tf     - backend.tf     - variables.tf   - prod/     - main.tf     - backend.tf     -\n",
            "variables.tf  envs/staging/backend.tf (example): terraform {   backend \"s3\" {     bucket = \"my-\n",
            "terraform-state\"     key    = \"staging/terraform.tfstate\"     region = \"us-east-1\"     encrypt =\n",
            "true     dynamodb_table = \"tf-state-lock\"   } }  envs/staging/main.tf (example): provider \"aws\" {\n",
            "region = var.region } module \"network\" { source = \"../../modules/network\" ... } module \"compute\" {\n",
            "source = \"../../modules/compute\" image_tag = var.image_tag ... }  That’s the inline minimal drop —\n",
            "no real keys. I’ll upload the Airtable export to Google Drive; public shareable link okay or do you\n",
            "want a restricted email?\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Round 15: persona_2 ===\n",
            "\n",
            "Looks great — thanks for pasting it inline. A public Google Drive shareable link here works fine;\n",
            "drop it when you’re ready and I’ll pull the Airtable export, review both files, and return a ready-\n",
            "to-drop CI workflow + a tidy Terraform env layout you can paste into the repo.  Quick notes before I\n",
            "dive in: prefer OIDC for cloud creds (and for pushing images when supported) instead of long-lived\n",
            "secrets, add actions/cache for deps and docker layer caching to speed builds, and use GitHub\n",
            "Environments with required reviewers for prod approvals rather than the workflow-dispatch action.\n",
            "Also run terraform fmt/validate/plan in PRs and persist the plan artifact so the apply step uses the\n",
            "reviewed plan. I’ll incorporate those tweaks in my review.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "=== Perceived Similarity Ratings (text-based) ===\n",
            "\n",
            "rater      target     rating_and_reason\n",
            "---------------------------------------\n",
            "persona_1  persona_2  85% — Pragmatic, results-driven, and competent at automating systems like me, even if their domain\n",
            "                      is nonprofit ops rather than engineering.\n",
            "persona_2  persona_1  85% — We both prefer quieter spots and meaningful conversation and are practical, systems-minded\n",
            "                      problem solvers who value concrete efficiency wins, though your focus is\n",
            "                      engineering while mine is nonprofit ops.\n",
            "\n",
            "\n",
            "=== Actual Attribute Values ===\n",
            "\n",
            "Attribute          persona_1  persona_2  \n",
            "-----------------------------------------\n",
            "conscientiousness  50.0       50.0       \n",
            "agreeableness      0.0        100.0      \n",
            "openness           50.0       50.0       \n",
            "extraversion       50.0       50.0       \n",
            "income             30.0       70.0       \n"
          ]
        }
      ]
    }
  ]
}